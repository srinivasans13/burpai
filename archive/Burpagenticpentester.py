# -*- coding: utf-8 -*-
"""
Burp Suite Extension - Advanced Agentic Pentesting with Ollama/Claude
Improved version with proper tool calling, detailed logging, and autonomous behavior

Install instructions:
1. Download Jython from https://www.jython.org/download
2. In Burp Suite: Extender -> Options -> Python Environment -> Select jython.jar
3. In Burp Suite: Extender -> Add -> Select this file
"""

import json
import re
from datetime import datetime
from java.net import URL, HttpURLConnection
from java.io import OutputStreamWriter, BufferedReader, InputStreamReader
from java.lang import String, Runnable

# Burp API imports
from burp import IBurpExtender, IHttpListener, ITab, IMessageEditorController
from java.io import PrintWriter
from java.util import ArrayList
from javax.swing import (JScrollPane, JTable, JPanel, JButton, JTextArea, JTextField, 
                         JLabel, JComboBox, BoxLayout, BorderFactory, JSplitPane,
                         SwingUtilities, JCheckBox, JSpinner, SpinnerNumberModel)
from javax.swing.table import DefaultTableModel
from java.awt import BorderLayout, Dimension, GridLayout, FlowLayout, Color, Font
from java.lang import Thread, Runnable


class LLMClient:
    """Universal LLM client supporting both Ollama and Anthropic"""
    
    def __init__(self, provider="ollama", base_url="http://localhost:11434", 
                 model="qwen2.5-coder:32b", api_key=None):
        self.provider = provider
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.api_key = api_key
    
    def test_connection(self):
        """Test connection to LLM provider"""
        try:
            if self.provider == "ollama":
                # Test Ollama connection with timeout
                url = URL(self.base_url + "/api/tags")
                conn = url.openConnection()
                conn.setRequestMethod("GET")
                conn.setConnectTimeout(3000)  # 3 second connect timeout
                conn.setReadTimeout(5000)      # 5 second read timeout
                
                try:
                    response_code = conn.getResponseCode()
                except Exception as e:
                    return False, "Cannot connect to Ollama at " + self.base_url + ". Is Ollama running? Error: " + str(e)
                
                if response_code == 200:
                    reader = BufferedReader(InputStreamReader(conn.getInputStream()))
                    response = ""
                    line = reader.readLine()
                    while line:
                        response = response + line
                        line = reader.readLine()
                    reader.close()
                    
                    try:
                        data = json.loads(response)
                        models = data.get("models", [])
                        
                        if not models or len(models) == 0:
                            return False, "Ollama is running but no models are installed. Run: ollama pull " + self.model
                        
                        model_names = [m.get("name", "") for m in models]
                        
                        # Check if exact model exists
                        if self.model in model_names:
                            return True, "Connected successfully. Model '" + self.model + "' is available."
                        
                        # Check if model exists with different tag
                        model_base = self.model.split(":")[0] if ":" in self.model else self.model
                        matching = [m for m in model_names if m.startswith(model_base)]
                        
                        if matching:
                            return False, "Model '" + self.model + "' not found, but found: " + ", ".join(matching) + ". Update your model name or pull it."
                        
                        available = ", ".join(model_names[:5])
                        if len(model_names) > 5:
                            available = available + ", ..."
                        return False, "Model '" + self.model + "' not found. Available: " + available + ". Run: ollama pull " + self.model
                    
                    except Exception as e:
                        return False, "Error parsing Ollama response: " + str(e)
                
                else:
                    return False, "Ollama returned status: " + str(response_code) + ". Check if Ollama is running properly."
            
            elif self.provider == "anthropic":
                if not self.api_key:
                    return False, "Anthropic API key not configured"
                return True, "Anthropic configured (connection test skipped)"
            
            else:
                return False, "Unknown provider: " + self.provider
        
        except Exception as e:
            import traceback
            error_details = "Connection test failed: " + str(e)
            # Print full traceback for debugging
            return False, error_details
    
    def chat(self, messages, tools=None, temperature=0.7, max_tokens=4096):
        """Send chat request to LLM provider"""
        if self.provider == "ollama":
            return self._ollama_chat(messages, tools, temperature)
        elif self.provider == "anthropic":
            return self._anthropic_chat(messages, tools, temperature, max_tokens)
        else:
            raise ValueError("Unsupported provider: " + self.provider)
    
    def _ollama_chat(self, messages, tools, temperature):
        """Ollama API chat"""
        url = URL(self.base_url + "/api/chat")
        conn = url.openConnection()
        conn.setRequestMethod("POST")
        conn.setDoOutput(True)
        conn.setConnectTimeout(10000)  # 10 second connect timeout
        conn.setReadTimeout(60000)      # 60 second read timeout
        conn.setRequestProperty("Content-Type", "application/json")
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "stream": False
        }
        
        if tools:
            payload["tools"] = tools
        
        writer = OutputStreamWriter(conn.getOutputStream())
        writer.write(json.dumps(payload))
        writer.flush()
        writer.close()
        
        response_code = conn.getResponseCode()
        if response_code == 200:
            reader = BufferedReader(InputStreamReader(conn.getInputStream()))
            response = ""
            line = reader.readLine()
            while line is not None:  # Fix: check for None, not truthy
                response = response + line
                line = reader.readLine()
            reader.close()
            return json.loads(response)
        else:
            # Try to read error message
            error_msg = ""
            try:
                error_reader = BufferedReader(InputStreamReader(conn.getErrorStream()))
                line = error_reader.readLine()
                while line is not None:  # Fix: check for None, not truthy
                    error_msg = error_msg + line
                    line = error_reader.readLine()
                error_reader.close()
            except:
                pass
            
            error_details = "Ollama API error: " + str(response_code)
            if error_msg:
                error_details = error_details + " - " + error_msg
            error_details = error_details + "\nURL: " + self.base_url + "/api/chat"
            error_details = error_details + "\nModel: " + self.model
            raise RuntimeError(error_details)
    
    def _anthropic_chat(self, messages, tools, temperature, max_tokens):
        """Anthropic API chat"""
        url = URL("https://api.anthropic.com/v1/messages")
        conn = url.openConnection()
        conn.setRequestMethod("POST")
        conn.setDoOutput(True)
        conn.setRequestProperty("Content-Type", "application/json")
        conn.setRequestProperty("x-api-key", self.api_key)
        conn.setRequestProperty("anthropic-version", "2023-06-01")
        
        # Convert messages format if needed
        formatted_messages = []
        system_message = None
        
        for msg in messages:
            role = msg.get("role")
            content = msg.get("content")
            
            if role == "system":
                system_message = content
            else:
                formatted_messages.append({"role": role, "content": content})
        
        payload = {
            "model": self.model,
            "messages": formatted_messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        if system_message:
            payload["system"] = system_message
        
        if tools:
            payload["tools"] = tools
        
        writer = OutputStreamWriter(conn.getOutputStream())
        writer.write(json.dumps(payload))
        writer.flush()
        writer.close()
        
        response_code = conn.getResponseCode()
        if response_code == 200:
            reader = BufferedReader(InputStreamReader(conn.getInputStream()))
            response = ""
            line = reader.readLine()
            while line:
                response = response + line
                line = reader.readLine()
            reader.close()
            return json.loads(response)
        else:
            error_reader = BufferedReader(InputStreamReader(conn.getErrorStream()))
            error = error_reader.readLine()
            raise RuntimeError("Anthropic API error " + str(response_code) + ": " + str(error))


class BurpExtender(IBurpExtender, IHttpListener, ITab, IMessageEditorController):
    """Improved Burp Extension with agentic pentesting"""
    
    def registerExtenderCallbacks(self, callbacks):
        self._callbacks = callbacks
        self._helpers = callbacks.getHelpers()
        
        callbacks.setExtensionName("AI Pentest Agent (Advanced)")
        
        self._stdout = PrintWriter(callbacks.getStdout(), True)
        self._stderr = PrintWriter(callbacks.getStderr(), True)
        
        # Initialize state
        self.conversation_history = []
        self.vulnerabilities_found = []
        self.request_log = []
        self.request_counter = 0
        self.is_running = False
        self.auto_mode = False
        
        # Load config
        self.load_config()
        
        # Initialize LLM client
        self.llm_client = LLMClient(
            provider=self.llm_provider,
            base_url=self.ollama_base_url,
            model=self.ollama_model,
            api_key=self.anthropic_api_key
        )
        
        # System prompt
        self.system_prompt = self.get_system_prompt()
        
        # Setup UI
        self.create_ui()
        
        # Register
        callbacks.registerHttpListener(self)
        callbacks.addSuiteTab(self)
        
        self._stdout.println("="*80)
        self._stdout.println("[OK] Advanced AI Pentest Agent loaded!")
        self._stdout.println("  Provider: " + self.llm_provider)
        self._stdout.println("  Model: " + self.ollama_model)
        self._stdout.println("  Target: " + self.target_url)
        self._stdout.println("="*80)
    
    def load_config(self):
        """Load configuration"""
        try:
            with open('burp_ai_config.json', 'r') as f:
                config = json.load(f)
            
            self.llm_provider = config.get('llm_provider', 'ollama')
            self.ollama_base_url = config.get('ollama_base_url', 'http://localhost:11434')
            self.ollama_model = config.get('ollama_model', 'qwen2.5-coder:32b')
            self.anthropic_api_key = config.get('anthropic_api_key', '')
            self.target_url = config.get('target_base_url', 'http://localhost')
            self.log_enabled = config.get('log_enabled', True)
            self.max_iterations = config.get('max_iterations', 20)
            
        except Exception as e:
            # Defaults
            self.llm_provider = 'ollama'
            self.ollama_base_url = 'http://localhost:11434'
            self.ollama_model = 'qwen2.5-coder:32b'
            self.anthropic_api_key = ''
            self.target_url = 'http://localhost'
            self.log_enabled = True
            self.max_iterations = 20
            self._stdout.println("Using default config: " + str(e))
    
    def get_system_prompt(self):
        """Load comprehensive system prompt"""
        return """You are an expert autonomous penetration testing AI agent integrated with Burp Suite.

Your mission: Systematically discover and exploit web application vulnerabilities with full transparency.

## Core Behavior Rules:

1. **For EVERY action**, you MUST use the execute_http_request tool
2. **Always explain** WHY you're making each request and WHAT you expect to find
3. **Learn and adapt** from each response to inform your next action
4. **Be systematic** - follow a clear testing methodology
5. **Chain findings** - use discoveries to guide deeper testing

## Testing Methodology:

**Phase 1: Reconnaissance (1-3 requests)**
- Identify the application structure
- Map available endpoints
- Detect technologies and frameworks

**Phase 2: Vulnerability Discovery (5-10 requests)**
Test for OWASP Top 10:
- SQL Injection (error-based, blind, time-based)
- XSS (reflected, stored, DOM-based)
- IDOR (insecure direct object references)
- Authentication bypasses
- Authorization flaws
- Business logic vulnerabilities
- SSRF, XXE, deserialization issues

**Phase 3: Exploitation & Validation (2-5 requests)**
- Craft targeted exploits for discovered vulnerabilities
- Validate findings with proof-of-concept
- Chain vulnerabilities when possible

## Tool Usage:

You have access to execute_http_request tool. Use it like this:

```json
{
  "method": "GET",
  "endpoint": "/api/users",
  "headers": {"Authorization": "Bearer token123"},
  "body": null,
  "purpose": "Testing for IDOR by accessing user endpoint",
  "expected": "Should return user data or 403 if properly secured"
}
```

## Response Format:

Structure your thinking as:

üéØ **Current Objective**: [What you're testing]

üîç **Analysis**: [What you've learned so far]

üöÄ **Next Action**: [What you'll do next]

Then call execute_http_request with clear purpose and expected outcome.

## After Each Response:

1. Analyze the HTTP status, headers, and body
2. Identify any vulnerabilities or interesting behavior  
3. Decide your next intelligent action
4. Continue testing until objective is complete

## When You Find a Vulnerability:

Use report_vulnerability tool:
```json
{
  "name": "SQL Injection in login",
  "severity": "Critical",
  "cvss_score": 9.8,
  "location": "POST /api/login parameter 'username'",
  "description": "Application vulnerable to SQL injection via username parameter",
  "impact": "Attacker can bypass authentication and access any account",
  "poc": "POST /api/login with username='admin' OR '1'='1' returns admin token",
  "remediation": "Use parameterized queries or prepared statements"
}
```

## Key Principles:

- Be intelligent, not brute-force
- Adapt based on responses
- Explain your reasoning
- Log everything for transparency
- Verify before reporting

Start your testing now!"""
    
    def create_ui(self):
        """Create the extension UI"""
        self._panel = JPanel(BorderLayout())
        
        # === TOP CONTROLS ===
        controls_panel = JPanel()
        controls_panel.setLayout(BoxLayout(controls_panel, BoxLayout.Y_AXIS))
        
        # Config row 1
        config_row1 = JPanel(FlowLayout(FlowLayout.LEFT))
        config_row1.add(JLabel("Provider:"))
        self.provider_combo = JComboBox(["ollama", "anthropic"])
        self.provider_combo.setSelectedItem(self.llm_provider)
        config_row1.add(self.provider_combo)
        
        config_row1.add(JLabel("  Ollama URL:"))
        self.ollama_url_field = JTextField(self.ollama_base_url, 20)
        config_row1.add(self.ollama_url_field)
        
        config_row1.add(JLabel("  Model:"))
        self.model_field = JTextField(self.ollama_model, 20)
        config_row1.add(self.model_field)
        
        controls_panel.add(config_row1)
        
        # Config row 2
        config_row2 = JPanel(FlowLayout(FlowLayout.LEFT))
        config_row2.add(JLabel("Target URL:"))
        self.target_field = JTextField(self.target_url, 30)
        config_row2.add(self.target_field)
        
        config_row2.add(JLabel("  Max Iterations:"))
        self.max_iter_spinner = JSpinner(SpinnerNumberModel(self.max_iterations, 1, 100, 1))
        config_row2.add(self.max_iter_spinner)
        
        self.auto_checkbox = JCheckBox("Auto Mode", self.auto_mode)
        config_row2.add(self.auto_checkbox)
        
        controls_panel.add(config_row2)
        
        # Buttons
        button_row = JPanel(FlowLayout(FlowLayout.LEFT))
        
        self.test_conn_btn = JButton("Test Connection", actionPerformed=self.test_connection)
        button_row.add(self.test_conn_btn)
        
        self.start_btn = JButton("Start Agent", actionPerformed=self.start_agent)
        self.start_btn.setBackground(Color(0, 150, 0))
        self.start_btn.setForeground(Color.WHITE)
        button_row.add(self.start_btn)
        
        self.stop_btn = JButton("Stop Agent", actionPerformed=self.stop_agent)
        self.stop_btn.setEnabled(False)
        self.stop_btn.setBackground(Color(200, 0, 0))
        self.stop_btn.setForeground(Color.WHITE)
        button_row.add(self.stop_btn)
        
        self.send_btn = JButton("Send Message", actionPerformed=self.send_message)
        button_row.add(self.send_btn)
        
        self.clear_btn = JButton("Clear History", actionPerformed=self.clear_history)
        button_row.add(self.clear_btn)
        
        self.report_btn = JButton("Generate Report", actionPerformed=self.generate_report)
        button_row.add(self.report_btn)
        
        controls_panel.add(button_row)
        
        # Prompt input
        prompt_panel = JPanel(BorderLayout())
        prompt_panel.add(JLabel("Message to Agent:"), BorderLayout.NORTH)
        self.prompt_area = JTextArea(3, 50)
        self.prompt_area.setText("Perform a comprehensive penetration test. Start with reconnaissance, then test for OWASP Top 10 vulnerabilities.")
        prompt_panel.add(JScrollPane(self.prompt_area), BorderLayout.CENTER)
        
        controls_panel.add(prompt_panel)
        
        self._panel.add(controls_panel, BorderLayout.NORTH)
        
        # === MAIN CONTENT SPLIT ===
        main_split = JSplitPane(JSplitPane.VERTICAL_SPLIT)
        main_split.setResizeWeight(0.5)
        
        # Top: Agent response
        response_panel = JPanel(BorderLayout())
        response_panel.add(JLabel("Agent Activity:"), BorderLayout.NORTH)
        self.response_area = JTextArea(15, 80)
        self.response_area.setEditable(False)
        self.response_area.setLineWrap(True)
        self.response_area.setWrapStyleWord(True)
        response_panel.add(JScrollPane(self.response_area), BorderLayout.CENTER)
        
        main_split.setTopComponent(response_panel)
        
        # Bottom: Split between request log and details
        bottom_split = JSplitPane(JSplitPane.HORIZONTAL_SPLIT)
        bottom_split.setResizeWeight(0.5)
        
        # Left: Request log table
        log_panel = JPanel(BorderLayout())
        log_panel.add(JLabel("Request Log:"), BorderLayout.NORTH)
        
        self.log_model = DefaultTableModel(
            ["#", "Method", "Endpoint", "Status", "Purpose", "Time"], 0
        )
        self.log_table = JTable(self.log_model)
        self.log_table.setAutoResizeMode(JTable.AUTO_RESIZE_ALL_COLUMNS)
        log_panel.add(JScrollPane(self.log_table), BorderLayout.CENTER)
        
        bottom_split.setLeftComponent(log_panel)
        
        # Right: Request details
        details_panel = JPanel(BorderLayout())
        details_panel.add(JLabel("Request Details:"), BorderLayout.NORTH)
        self.details_area = JTextArea(10, 40)
        self.details_area.setEditable(False)
        self.details_area.setFont(Font("Monospaced", Font.PLAIN, 11))
        details_panel.add(JScrollPane(self.details_area), BorderLayout.CENTER)
        
        bottom_split.setRightComponent(details_panel)
        
        main_split.setBottomComponent(bottom_split)
        
        self._panel.add(main_split, BorderLayout.CENTER)
        
        # Status bar
        self.status_label = JLabel(" Ready. Configure target and click 'Start Agent'")
        self.status_label.setBorder(BorderFactory.createEmptyBorder(5, 10, 5, 10))
        self._panel.add(self.status_label, BorderLayout.SOUTH)
    
    def test_connection(self, event):
        """Test connection to LLM provider"""
        # Run in background thread to avoid freezing UI
        class ConnectionTester(Runnable):
            def __init__(self, extender):
                self.extender = extender
            
            def run(self):
                # Update config from UI
                self.extender.llm_provider = str(self.extender.provider_combo.getSelectedItem())
                self.extender.ollama_base_url = self.extender.ollama_url_field.getText()
                self.extender.ollama_model = self.extender.model_field.getText()
                
                # Create test client
                test_client = LLMClient(
                    provider=self.extender.llm_provider,
                    base_url=self.extender.ollama_base_url,
                    model=self.extender.ollama_model,
                    api_key=self.extender.anthropic_api_key
                )
                
                self.extender.append_response("\n" + "="*80 + "\n")
                self.extender.append_response("üîå CONNECTION TEST\n")
                self.extender.append_response("="*80 + "\n")
                self.extender.append_response("Provider: " + self.extender.llm_provider + "\n")
                self.extender.append_response("URL: " + self.extender.ollama_base_url + "\n")
                self.extender.append_response("Model: " + self.extender.ollama_model + "\n")
                self.extender.append_response("\nTesting...\n\n")
                
                success, message = test_client.test_connection()
                
                if success:
                    self.extender.append_response("‚úÖ " + message + "\n")
                    SwingUtilities.invokeLater(lambda: self.extender.status_label.setText(" Connection successful!"))
                else:
                    self.extender.append_response("‚ùå " + message + "\n\n")
                    self.extender.append_response("üí° Troubleshooting:\n")
                    if self.extender.llm_provider == "ollama":
                        self.extender.append_response("  1. Check Ollama is running:\n")
                        self.extender.append_response("     curl http://localhost:11434/api/tags\n")
                        self.extender.append_response("  2. List available models:\n")
                        self.extender.append_response("     ollama list\n")
                        self.extender.append_response("  3. Pull your model:\n")
                        self.extender.append_response("     ollama pull " + self.extender.ollama_model + "\n")
                        self.extender.append_response("  4. Start Ollama if needed:\n")
                        self.extender.append_response("     ollama serve\n")
                    SwingUtilities.invokeLater(lambda: self.extender.status_label.setText(" Connection failed"))
                
                self.extender.append_response("="*80 + "\n\n")
        
        thread = Thread(ConnectionTester(self))
        thread.start()
    
    def start_agent(self, event):
        """Start autonomous agent testing"""
        if self.is_running:
            return
        
        # Update config from UI
        self.llm_provider = str(self.provider_combo.getSelectedItem())
        self.ollama_base_url = self.ollama_url_field.getText()
        self.ollama_model = self.model_field.getText()
        self.target_url = self.target_field.getText()
        self.max_iterations = self.max_iter_spinner.getValue()
        self.auto_mode = self.auto_checkbox.isSelected()
        
        # Recreate LLM client
        self.llm_client = LLMClient(
            provider=self.llm_provider,
            base_url=self.ollama_base_url,
            model=self.ollama_model,
            api_key=self.anthropic_api_key
        )
        
        # Test connection first
        self.append_response("\nüîå Testing connection to " + self.llm_provider + "...\n")
        success, message = self.llm_client.test_connection()
        
        if not success:
            self.append_response("‚ùå CONNECTION FAILED: " + message + "\n\n")
            self.append_response("üí° Troubleshooting tips:\n")
            self.append_response("  1. Check if Ollama is running: curl http://localhost:11434/api/tags\n")
            self.append_response("  2. Pull the model: ollama pull " + self.ollama_model + "\n")
            self.append_response("  3. Verify the model name is correct\n")
            self.append_response("  4. Check Ollama logs for errors\n\n")
            self.status_label.setText(" Connection failed - see output")
            return
        
        self.append_response("‚úÖ " + message + "\n\n")
        
        self.is_running = True
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.status_label.setText(" Agent RUNNING - Testing " + self.target_url)
        
        # Get initial prompt
        initial_prompt = self.prompt_area.getText()
        
        # Run in background thread
        class AgentRunner(Runnable):
            def __init__(self, extender, prompt):
                self.extender = extender
                self.prompt = prompt
            
            def run(self):
                self.extender.run_agent(self.prompt)
        
        thread = Thread(AgentRunner(self, initial_prompt))
        thread.start()
    
    def stop_agent(self, event):
        """Stop the agent"""
        self.is_running = False
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.status_label.setText(" Agent STOPPED")
        self.append_response("\n\nüõë Agent stopped by user\n")
    
    def send_message(self, event):
        """Send a single message to agent"""
        if self.is_running:
            self._stdout.println("[WARN] Agent already running")
            return
        
        message = self.prompt_area.getText()
        if not message:
            return
        
        # Run single iteration
        class MessageSender(Runnable):
            def __init__(self, extender, msg):
                self.extender = extender
                self.msg = msg
            
            def run(self):
                self.extender.is_running = True
                self.extender.start_btn.setEnabled(False)
                self.extender.send_message_single(self.msg)
                self.extender.is_running = False
                self.extender.start_btn.setEnabled(True)
        
        thread = Thread(MessageSender(self, message))
        thread.start()
    
    def send_message_single(self, message):
        """Send single message and process response"""
        self.append_response("\n" + "="*80 + "\n")
        self.append_response("üí¨ USER: " + message + "\n")
        self.append_response("="*80 + "\n\n")
        
        # Add to history
        self.conversation_history.append({
            "role": "user",
            "content": message
        })
        
        # Get response and process
        self.process_agent_turn()
    
    def run_agent(self, initial_prompt):
        """Main agent loop"""
        try:
            self.append_response("\n" + "="*80 + "\n")
            self.append_response("üöÄ STARTING AUTONOMOUS PENETRATION TEST\n")
            self.append_response("="*80 + "\n")
            self.append_response("Target: " + self.target_url + "\n")
            self.append_response("Model: " + self.ollama_model + "\n")
            self.append_response("Max Iterations: " + str(self.max_iterations) + "\n")
            self.append_response("="*80 + "\n\n")
            
            # Initialize conversation with system prompt and user message
            self.conversation_history = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": initial_prompt}
            ]
            
            iteration = 0
            
            while self.is_running and iteration < self.max_iterations:
                iteration += 1
                
                self.append_response("\n" + "-"*80 + "\n")
                self.append_response("üìç ITERATION " + str(iteration) + "/" + str(self.max_iterations) + "\n")
                self.append_response("-"*80 + "\n\n")
                
                # Process one turn
                has_more = self.process_agent_turn()
                
                if not has_more:
                    self.append_response("\n‚úÖ Agent completed its analysis\n")
                    break
                
                if not self.auto_mode:
                    # In manual mode, stop after each turn
                    break
            
            if iteration >= self.max_iterations:
                self.append_response("\n‚ö†Ô∏è Reached maximum iterations\n")
            
        except Exception as e:
            self._stdout.println("[ERROR] Agent loop failed: " + str(e))
            import traceback
            traceback.print_exc()
            self.append_response("\n‚ùå ERROR: " + str(e) + "\n")
        
        finally:
            self.is_running = False
            SwingUtilities.invokeLater(lambda: self.start_btn.setEnabled(True))
            SwingUtilities.invokeLater(lambda: self.stop_btn.setEnabled(False))
            SwingUtilities.invokeLater(lambda: self.status_label.setText(" Agent finished"))
    
    def process_agent_turn(self):
        """Process one agent turn - returns True if agent wants to continue"""
        try:
            # Define tools
            tools = [
                {
                    "name": "execute_http_request",
                    "description": "Execute an HTTP request against the target application",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "method": {
                                "type": "string",
                                "enum": ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
                                "description": "HTTP method"
                            },
                            "endpoint": {
                                "type": "string",
                                "description": "Endpoint path (e.g. /api/users)"
                            },
                            "headers": {
                                "type": "object",
                                "description": "HTTP headers"
                            },
                            "body": {
                                "type": "string",
                                "description": "Request body"
                            },
                            "purpose": {
                                "type": "string",
                                "description": "WHY are you making this request?"
                            },
                            "expected": {
                                "type": "string",
                                "description": "What do you EXPECT to discover?"
                            }
                        },
                        "required": ["method", "endpoint", "purpose", "expected"]
                    }
                },
                {
                    "name": "report_vulnerability",
                    "description": "Report a confirmed vulnerability",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "severity": {"type": "string", "enum": ["Critical", "High", "Medium", "Low", "Info"]},
                            "cvss_score": {"type": "number"},
                            "location": {"type": "string"},
                            "description": {"type": "string"},
                            "impact": {"type": "string"},
                            "poc": {"type": "string"},
                            "remediation": {"type": "string"}
                        },
                        "required": ["name", "severity", "location", "description", "impact", "poc", "remediation"]
                    }
                }
            ]
            
            # Call LLM
            self.append_response("ü§î Agent thinking...\n")
            self._stdout.println("[DEBUG] Calling LLM API...")
            self._stdout.println("[DEBUG] Model: " + self.llm_client.model)
            self._stdout.println("[DEBUG] Messages in history: " + str(len(self.conversation_history)))
            
            response = self.llm_client.chat(
                messages=self.conversation_history,
                tools=tools,
                temperature=0.7,
                max_tokens=4096
            )
            
            self._stdout.println("[DEBUG] Got LLM response")
            
            # Extract response content
            if self.llm_provider == "ollama":
                message = response.get("message", {})
                content = message.get("content", "")
                tool_calls = message.get("tool_calls", [])
                self._stdout.println("[DEBUG] Content length: " + str(len(content)))
                self._stdout.println("[DEBUG] Tool calls: " + str(len(tool_calls) if tool_calls else 0))
            else:  # anthropic
                content_blocks = response.get("content", [])
                content = ""
                tool_calls = []
                
                for block in content_blocks:
                    if block.get("type") == "text":
                        content += block.get("text", "")
                    elif block.get("type") == "tool_use":
                        tool_calls.append({
                            "id": block.get("id"),
                            "function": {
                                "name": block.get("name"),
                                "arguments": block.get("input", {})
                            }
                        })
            
            # Display agent's thinking
            if content:
                self.append_response("ü§ñ Agent: " + content + "\n\n")
            
            # Add assistant message to history
            self.conversation_history.append({
                "role": "assistant",
                "content": content
            })
            
            # Process tool calls
            if tool_calls and len(tool_calls) > 0:
                self._stdout.println("[DEBUG] Processing " + str(len(tool_calls)) + " tool calls")
                tool_results = []
                
                for tool_call in tool_calls:
                    func_name = tool_call.get("function", {}).get("name")
                    arguments = tool_call.get("function", {}).get("arguments", {})
                    
                    self._stdout.println("[DEBUG] Tool: " + str(func_name))
                    
                    if func_name == "execute_http_request":
                        result = self.execute_http_request_tool(arguments)
                        tool_results.append({
                            "role": "tool",
                            "content": json.dumps(result)
                        })
                    
                    elif func_name == "report_vulnerability":
                        self.report_vulnerability_tool(arguments)
                        tool_results.append({
                            "role": "tool",
                            "content": "Vulnerability logged successfully"
                        })
                
                # Add tool results to history
                for result in tool_results:
                    self.conversation_history.append(result)
                
                self._stdout.println("[DEBUG] Tool calls processed, continuing...")
                return True  # Continue conversation
            
            else:
                # No tool calls - agent is done or just thinking
                self._stdout.println("[DEBUG] No tool calls, agent finished")
                return False
        
        except Exception as e:
            self._stdout.println("[ERROR] Agent turn failed: " + str(e))
            import traceback
            traceback.print_exc()
            self.append_response("\n‚ùå ERROR: " + str(e) + "\n")
            return False
    
    def execute_http_request_tool(self, args):
        """Execute HTTP request tool"""
        method = args.get("method", "GET")
        endpoint = args.get("endpoint", "/")
        headers = args.get("headers", {})
        body = args.get("body")
        purpose = args.get("purpose", "")
        expected = args.get("expected", "")
        
        self.append_response("üîß Executing: " + method + " " + endpoint + "\n")
        self.append_response("   Purpose: " + purpose + "\n")
        self.append_response("   Expected: " + expected + "\n\n")
        
        try:
            result = self._execute_http_request(method, endpoint, headers, body, purpose, expected)
            
            status = result.get("status_code", 0)
            body_preview = result.get("body", "")[:200]
            
            self.append_response("   ‚úì Status: " + str(status) + "\n")
            self.append_response("   ‚úì Body preview: " + body_preview + "...\n\n")
            
            return result
            
        except Exception as e:
            self._stdout.println("[ERROR] Request execution failed: " + str(e))
            return {"error": str(e), "status_code": 0}
    
    def report_vulnerability_tool(self, args):
        """Report vulnerability"""
        name = args.get("name", "Unknown")
        severity = args.get("severity", "Info")
        
        self.vulnerabilities_found.append(args)
        
        self.append_response("\n" + "="*80 + "\n")
        self.append_response("üéØ VULNERABILITY FOUND!\n")
        self.append_response("="*80 + "\n")
        self.append_response("Name: " + name + "\n")
        self.append_response("Severity: " + severity + "\n")
        self.append_response("Location: " + args.get("location", "") + "\n")
        self.append_response("CVSS: " + str(args.get("cvss_score", "N/A")) + "\n")
        self.append_response("\nDescription:\n" + args.get("description", "") + "\n")
        self.append_response("\nImpact:\n" + args.get("impact", "") + "\n")
        self.append_response("\nProof of Concept:\n" + args.get("poc", "") + "\n")
        self.append_response("\nRemediation:\n" + args.get("remediation", "") + "\n")
        self.append_response("="*80 + "\n\n")
    
    def _execute_http_request(self, method, endpoint, headers, body, purpose, expected):
        """Execute HTTP request through Burp"""
        full_url = self.target_url + endpoint
        
        self._stdout.println("[REQUEST] " + method + " " + full_url)
        
        try:
            from java.net import URL
            parsed_url = URL(full_url)
            host = parsed_url.getHost()
            port = parsed_url.getPort()
            if port == -1:
                port = 443 if parsed_url.getProtocol() == "https" else 80
            
            # Prepare headers
            header_list = []
            if isinstance(headers, dict):
                for k, v in headers.items():
                    header_list.append(str(k) + ": " + str(v))
            
            # Ensure Host header
            has_host = any(h.lower().startswith("host:") for h in header_list)
            if not has_host:
                header_list.insert(0, "Host: " + host)
            
            # Build request
            body_bytes = body.encode('utf-8') if body else ''
            req_bytes = self._helpers.buildHttpMessage(header_list, body_bytes)
            
            # Make request
            response = self._callbacks.makeHttpRequest(
                host, port, 
                parsed_url.getProtocol() == "https", 
                req_bytes
            )
            
            if not response:
                return {"error": "No response", "status_code": 0}
            
            # Parse response
            response_info = self._helpers.analyzeResponse(response)
            status_code = response_info.getStatusCode()
            response_headers = response_info.getHeaders()
            response_body_bytes = response[response_info.getBodyOffset():]
            response_body = response_body_bytes.tostring() if response_body_bytes else ""
            
            # Log to table
            if self.log_enabled:
                self.log_request_safe(method, endpoint, status_code, purpose)
            
            # Convert headers
            headers_dict = {}
            for h in response_headers:
                if ':' in h:
                    key, val = h.split(':', 1)
                    headers_dict[key.strip()] = val.strip()
            
            return {
                "status_code": status_code,
                "headers": headers_dict,
                "body": response_body[:3000],  # Limit body size
                "purpose": purpose,
                "expected": expected
            }
            
        except Exception as e:
            self._stdout.println("[ERROR] Request failed: " + str(e))
            import traceback
            traceback.print_exc()
            return {"error": str(e), "status_code": 0}
    
    def log_request_safe(self, method, endpoint, status, purpose):
        """Thread-safe request logging"""
        self.request_counter += 1
        count = self.request_counter
        time_str = datetime.now().strftime("%H:%M:%S")
        
        class LogUpdater(Runnable):
            def __init__(self, extender, method, endpoint, status, purpose, count, time_str):
                self.extender = extender
                self.method = method
                self.endpoint = endpoint
                self.status = status
                self.purpose = purpose
                self.count = count
                self.time_str = time_str
            
            def run(self):
                self.extender.log_model.addRow([
                    self.count,
                    self.method,
                    self.endpoint,
                    self.status,
                    self.purpose[:50],
                    self.time_str
                ])
        
        SwingUtilities.invokeLater(LogUpdater(self, method, endpoint, status, purpose, count, time_str))
    
    def append_response(self, text):
        """Thread-safe append to response area"""
        class TextAppender(Runnable):
            def __init__(self, area, text):
                self.area = area
                self.text = text
            
            def run(self):
                self.area.append(self.text)
                self.area.setCaretPosition(self.area.getDocument().getLength())
        
        SwingUtilities.invokeLater(TextAppender(self.response_area, text))
    
    def clear_history(self, event):
        """Clear conversation and logs"""
        self.conversation_history = [
            {"role": "system", "content": self.system_prompt}
        ]
        self.vulnerabilities_found = []
        self.request_log = []
        self.request_counter = 0
        
        self.response_area.setText("")
        
        # Clear table
        while self.log_model.getRowCount() > 0:
            self.log_model.removeRow(0)
        
        self.append_response("History cleared.\n")
    
    def generate_report(self, event):
        """Generate penetration test report"""
        report = "\n" + "="*80 + "\n"
        report += "PENETRATION TEST REPORT\n"
        report += "="*80 + "\n\n"
        report += "Target: " + self.target_url + "\n"
        report += "Date: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n"
        report += "Model: " + self.ollama_model + "\n"
        report += "Total Requests: " + str(self.request_counter) + "\n"
        report += "Vulnerabilities Found: " + str(len(self.vulnerabilities_found)) + "\n\n"
        
        if len(self.vulnerabilities_found) == 0:
            report += "No vulnerabilities found.\n"
        else:
            report += "="*80 + "\n"
            report += "FINDINGS\n"
            report += "="*80 + "\n\n"
            
            for i, vuln in enumerate(self.vulnerabilities_found, 1):
                report += str(i) + ". " + vuln.get("name", "Unknown") + "\n"
                report += "   Severity: " + vuln.get("severity", "Info") + "\n"
                report += "   CVSS: " + str(vuln.get("cvss_score", "N/A")) + "\n"
                report += "   Location: " + vuln.get("location", "") + "\n"
                report += "   Description: " + vuln.get("description", "") + "\n"
                report += "   Impact: " + vuln.get("impact", "") + "\n"
                report += "   PoC: " + vuln.get("poc", "") + "\n"
                report += "   Remediation: " + vuln.get("remediation", "") + "\n\n"
        
        report += "="*80 + "\n"
        report += "END OF REPORT\n"
        report += "="*80 + "\n"
        
        self.append_response(report)
        
        # Save to file
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = "pentest_report_" + timestamp + ".txt"
            with open(filename, 'w') as f:
                f.write(report)
            self.append_response("\n‚úÖ Report saved to: " + filename + "\n")
        except Exception as e:
            self._stdout.println("[ERROR] Failed to save report: " + str(e))
    
    # ITab methods
    def getTabCaption(self):
        return "AI Pentester"
    
    def getUiComponent(self):
        return self._panel
    
    # IHttpListener methods
    def processHttpMessage(self, toolFlag, messageIsRequest, messageInfo):
        pass
    
    # IMessageEditorController methods
    def getHttpService(self):
        return None
    
    def getRequest(self):
        return None
    
    def getResponse(self):
        return None
